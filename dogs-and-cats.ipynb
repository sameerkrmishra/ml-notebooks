{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "To identify a given image is of a cat's or a dog's.\n",
    "\n",
    "Problem statement can be found here:\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "from functools import partial\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from scipy import misc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the images\n",
    "creating thumbnails from the original images of size (64x64) so that they're easier to process in a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_thumbnail(filename, dirname, targetdir, size):\n",
    "    image = Image.open(os.path.join(dirname, filename))\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    background = Image.new('RGBA', size, (255,255,255,0)) # Creating a white color background for the image\n",
    "    background.paste( image, ((size[0]-image.size[0])/2, (size[1]-image.size[1])/2) )\n",
    "    background.save(os.path.join(targetdir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thumbnails created for training images.\n"
     ]
    }
   ],
   "source": [
    "imgdir = 'train'\n",
    "thumbdir = 'train-thumbnails'\n",
    "thumb_create = partial(create_thumbnail, dirname=imgdir, targetdir=thumbdir, size=size)\n",
    "map(thumb_create, os.listdir(imgdir))\n",
    "print 'Thumbnails created for training images.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training and test images in numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(filepath):\n",
    "    image = misc.imread(filepath)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_img_names = os.listdir('train-thumbnails')\n",
    "test_img_names = os.listdir('test-thumbnails')\n",
    "all_train = np.array( map(load_image, map(lambda x: os.path.join('train-thumbnails', x), train_img_names) ) )\n",
    "all_train_labels = map(lambda x: x.split('.', 1)[0], train_img_names)\n",
    "all_train_labels = map(lambda x: 0 if x=='dog' else 1, all_train_labels)\n",
    "all_train_labels = np.array(all_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x, cv_x, train_y, cv_y = train_test_split(all_train, all_train_labels, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = np.eye(2)[train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_y = np.eye(2)[cv_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64, 64, 3), (2,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape, train_y[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and training a neural network with the image thumbnails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a CNN using keras\n",
    "model = Sequential()\n",
    "model.add( Convolution2D (\n",
    "                32, # number of filters\n",
    "                3, 3, # Convolution size\n",
    "                border_mode = 'valid',\n",
    "                input_shape = (64,64,3),\n",
    "                W_regularizer = l2(0.01)\n",
    "        ))\n",
    "model.add( BatchNormalization() )\n",
    "model.add( Activation('relu') )\n",
    "model.add( Convolution2D( 32, 3, 3, W_regularizer = l2(0.01) ) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( Activation('relu') )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Convolution2D( 64, 3, 3, W_regularizer = l2(0.01) ) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( Activation('relu') )\n",
    "model.add( Convolution2D( 64, 3, 3, W_regularizer = l2(0.01) ) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( Activation('relu') )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Convolution2D( 128, 3, 3, W_regularizer = l2(0.01)) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( Activation('relu') )\n",
    "model.add( Convolution2D(128, 3, 3, W_regularizer = l2(0.01)) )\n",
    "model.add( BatchNormalization() )\n",
    "model.add( Activation('relu') )\n",
    "model.add( MaxPooling2D( pool_size=(2,2) ) )\n",
    "model.add( Dropout(0.25) )\n",
    "\n",
    "model.add( Flatten() )\n",
    "\n",
    "model.add( Dense( 128, W_regularizer = l2(0.01) ) )\n",
    "model.add( Activation('relu') )\n",
    "model.add( Dropout(0.5) )\n",
    "\n",
    "model.add( Dense( 2, W_regularizer = l2(0.01) ) )\n",
    "model.add( Activation('sigmoid') )\n",
    "\n",
    "sgd = SGD(lr = 1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20000/20000 [==============================] - 1367s - loss: 3.2910 - acc: 0.6051  \n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 1294s - loss: 3.1623 - acc: 0.6719  \n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 1216s - loss: 3.0559 - acc: 0.7077  \n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 1255s - loss: 2.9744 - acc: 0.7274  \n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 1259s - loss: 2.8770 - acc: 0.7510  \n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 1244s - loss: 2.7948 - acc: 0.7677  \n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 1272s - loss: 2.7165 - acc: 0.7782  \n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 1262s - loss: 2.6412 - acc: 0.7925  \n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 1260s - loss: 2.5671 - acc: 0.7998  \n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 1272s - loss: 2.5022 - acc: 0.8125  \n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 1253s - loss: 2.4344 - acc: 0.8199  \n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 1247s - loss: 2.3729 - acc: 0.8287  \n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 1271s - loss: 2.3092 - acc: 0.8373  \n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 1292s - loss: 2.2507 - acc: 0.8419  \n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 1240s - loss: 2.1881 - acc: 0.8498  \n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 1296s - loss: 2.1375 - acc: 0.8532  \n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 1250s - loss: 2.0807 - acc: 0.8596  \n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 1266s - loss: 2.0291 - acc: 0.8631  \n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 1290s - loss: 1.9843 - acc: 0.8668  \n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 1277s - loss: 1.9338 - acc: 0.8742  \n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 1210s - loss: 1.8904 - acc: 0.8751  \n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 1284s - loss: 1.8430 - acc: 0.8810  \n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 1306s - loss: 1.8021 - acc: 0.8824  \n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 1273s - loss: 1.7576 - acc: 0.8863  \n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 1251s - loss: 1.7189 - acc: 0.8909  \n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 1233s - loss: 1.6777 - acc: 0.8911  \n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 1235s - loss: 1.6385 - acc: 0.8944  \n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 1237s - loss: 1.6001 - acc: 0.8964  \n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 1243s - loss: 1.5686 - acc: 0.8948  \n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 1231s - loss: 1.5299 - acc: 0.8979  \n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 1269s - loss: 1.4920 - acc: 0.9035  \n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 1217s - loss: 1.4595 - acc: 0.9032  \n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 1241s - loss: 1.4288 - acc: 0.9035  \n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 1240s - loss: 1.3946 - acc: 0.9093  \n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 1268s - loss: 1.3656 - acc: 0.9088  \n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 1221s - loss: 1.3307 - acc: 0.9135  \n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 1229s - loss: 1.3079 - acc: 0.9103  \n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 1249s - loss: 1.2733 - acc: 0.9158  \n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 1261s - loss: 1.2462 - acc: 0.9163  \n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 1251s - loss: 1.2216 - acc: 0.9189  \n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 1269s - loss: 1.1901 - acc: 0.9201  \n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 1237s - loss: 1.1664 - acc: 0.9210  \n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 1258s - loss: 1.1430 - acc: 0.9211  \n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 1268s - loss: 1.1149 - acc: 0.9247  \n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 1269s - loss: 1.0940 - acc: 0.9270  \n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 1234s - loss: 1.0683 - acc: 0.9282  \n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 1287s - loss: 1.0483 - acc: 0.9270  \n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 1286s - loss: 1.0184 - acc: 0.9288  \n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 1238s - loss: 0.9968 - acc: 0.9325  \n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 1280s - loss: 0.9835 - acc: 0.9306  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fabc76990d0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=32, nb_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 74s    \n",
      "Accuracy: 0.8908\n",
      "Loss: 0.272850845385\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate( cv_x, cv_y )\n",
    "print 'Accuracy:', accuracy\n",
    "print 'Loss:', loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### Achieved almost 90% accuracy on cross validation with Convolutional Neural Network"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
